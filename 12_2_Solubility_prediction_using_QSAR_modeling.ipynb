{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is Solubility and Why is it Important in Drug Discovery?\n",
        "Solubility refers to the ability of a substance (such as a drug compound) to dissolve in a solvent, typically water. In the context of pharmaceuticals, aqueous solubility is a critical property that influences a drug's absorption, distribution, and overall effectiveness.\n",
        "\n",
        "**Importance of solubility in Drug Discovery and Development:**\n",
        "\n",
        "*   **Bioavailability:** Poorly soluble drugs often exhibit low bioavailability,meaning less of the drug reaches systemic circulation.\n",
        "*   **Formulation Challenges:** Low solubility complicates drug formulation and delivery (e.g., oral tablets).\n",
        "*   **ADMET Profile:** Solubility is closely tied to Absorption, Distribution, Metabolism, Excretion, and Toxicity (ADMET) properties.\n",
        "*   **Lead Optimization:** During drug design, solubility is optimized alongside potency and selectivity to develop a balanced drug candidate.\n",
        "\n",
        "**Prediction via QSAR:**\n",
        "\n",
        "Quantitative Structure–Activity Relationship (QSAR) models help predict solubility using molecular descriptors, enabling faster screening of compounds in silico before synthesis or testing.\n"
      ],
      "metadata": {
        "id": "N0ht0n3vohiP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6E6vV4jgTGg"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tTTCdMgXPpY"
      },
      "source": [
        "**Now we will use RDKIT to build a regresison based QSAR model to predict solubility of compounds.**\n",
        "\n",
        "Here we will make a QSAR model which can predict the solubility of given set of compounds using various descriptors like logp , molecular weight , rotatable bonds and aromatic proportion.\n",
        "\n",
        "The dataset used is from the paper ESOL:  Estimating Aqueous Solubility Directly from Molecular Structure, John S. Delaney, Journal of Chemical Information and Computer Sciences 2004 44 (3), 1000-1005\n",
        "DOI: 10.1021/ci034243x (https://pubs.acs.org/doi/10.1021/ci034243x)\n",
        "\n",
        "John S. Delaney introduced the ESOL model, a straightforward method for predicting the aqueous solubility of compounds directly from their molecular structures. Utilizing linear regression on a dataset of 2,874 compounds, the model incorporates nine molecular descriptors, with calculated logP (octanol-water partition coefficient) being the most significant, followed by molecular weight, aromatic atom proportion, and the number of rotatable bonds. ESOL demonstrated consistent performance across three validation sets, predicting solubility within a factor of 5–8 of measured values, making it competitive with the established General Solubility Equation for drug-like molecules ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4AGdwdb_2tA"
      },
      "outputs": [],
      "source": [
        "#Download the file contaning trainig data.\n",
        "url = \"https://raw.githubusercontent.com/Rajnishphe/AIDD-2022/main/ML%20Based%20QSAR/delaney.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz1EVs7DncXi"
      },
      "outputs": [],
      "source": [
        "#Downloading Input data to Build and train model\n",
        "#First we will upload the input solubility data to build and train the model\n",
        "#Reading the input data using pandas\n",
        "import pandas as pd\n",
        "sol = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5dHJq3Cngvx"
      },
      "outputs": [],
      "source": [
        "#Take a look at the input data\n",
        "sol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twl_WbXlnmDR"
      },
      "outputs": [],
      "source": [
        "#Take a look at the first structure\n",
        "from rdkit import Chem\n",
        "Chem.MolFromSmiles(sol.SMILES[1142])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozZ24Lxens2R"
      },
      "outputs": [],
      "source": [
        "#converting smiles to molecule list and Rdkit object list\n",
        "from rdkit import Chem\n",
        "mol_list= []\n",
        "for element in sol.SMILES:\n",
        "  mol = Chem.MolFromSmiles(element)\n",
        "  mol_list.append(mol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yru_Yi8ToODa"
      },
      "outputs": [],
      "source": [
        "#length of molecule list\n",
        "len(mol_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMp-dcLsX_tP"
      },
      "source": [
        "# Calculate Descriptors\n",
        "Extracting descriptors from structure, descriptors used are logP, molecular weight , number of rotatable bonds and aromatic proportion aromatic proportion calculated seperatley, others calculated using Rdkit\n",
        "\n",
        "**Some other packages beside RdKit to calulate descriptors**.\n",
        "\n",
        "https://github.com/mordred-descriptor/mordred\n",
        "\n",
        "https://github.com/ecrl/padelpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUstzYtboQUZ"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "# Define a function to calculate aromatic proportion\n",
        "def get_aromatic_proportion(mol):\n",
        "    aromatic_atoms = sum([1 for atom in mol.GetAtoms() if atom.GetIsAromatic()])\n",
        "    heavy_atoms = Descriptors.HeavyAtomCount(mol)\n",
        "    return aromatic_atoms / heavy_atoms if heavy_atoms > 0 else 0\n",
        "\n",
        "# Initialize empty lists for each descriptor\n",
        "mol_wt = []\n",
        "logp = []\n",
        "num_rot_bonds = []\n",
        "num_h_donors = []\n",
        "num_h_acceptors = []\n",
        "aromatic_proportion = []\n",
        "tpsa = []  # List to store TPSA values\n",
        "\n",
        "# Calculate descriptors\n",
        "for mol in mol_list:\n",
        "    if mol is not None:\n",
        "        mol_wt.append(Descriptors.MolWt(mol))\n",
        "        logp.append(Descriptors.MolLogP(mol))\n",
        "        num_rot_bonds.append(Descriptors.NumRotatableBonds(mol))\n",
        "        num_h_donors.append(Descriptors.NumHDonors(mol))  # Corrected here\n",
        "        num_h_acceptors.append(Descriptors.NumHAcceptors(mol))\n",
        "        aromatic_proportion.append(get_aromatic_proportion(mol))\n",
        "        tpsa.append(Descriptors.TPSA(mol))  # Add TPSA calculation here\n",
        "    else:\n",
        "        mol_wt.append(None)\n",
        "        logp.append(None)\n",
        "        num_rot_bonds.append(None)\n",
        "        num_h_donors.append(None)\n",
        "        num_h_acceptors.append(None)\n",
        "        aromatic_proportion.append(None)\n",
        "        tpsa.append(None)  # Handle None case for TPSA\n",
        "\n",
        "# Add descriptors to the dataframe\n",
        "sol['MolWt'] = mol_wt\n",
        "sol['LogP'] = logp\n",
        "sol['NumRotatableBonds'] = num_rot_bonds\n",
        "sol['NumHDonors'] = num_h_donors\n",
        "sol['NumHAcceptors'] = num_h_acceptors\n",
        "sol['AromaticProportion'] = aromatic_proportion\n",
        "sol['TPSA'] = tpsa  # Add TPSA to the DataFrame\n",
        "\n",
        "# Display the updated dataframe\n",
        "sol\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot pairwise scatter plot using Seaborn\n",
        "sns.pairplot(sol[['MolWt', 'LogP', 'TPSA', 'NumHDonors', 'NumHAcceptors', 'AromaticProportion']])\n",
        "\n",
        "# Add title\n",
        "plt.suptitle('Pairwise Relationship between Descriptors', y=1.02)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L9Rb1u6-qlVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'sol' is your DataFrame containing the solubility data\n",
        "X = sol[['MolWt', 'LogP', 'TPSA', 'NumHDonors', 'NumHAcceptors', 'AromaticProportion']]  # Features\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = X.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6txPmuWkzyby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMVXUoRLpNkH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Features and Target variable\n",
        "X = sol[['MolWt', 'LogP', 'NumRotatableBonds', 'NumHDonors', 'NumHAcceptors', 'AromaticProportion']]  # Features\n",
        "y = sol['measured log(solubility:mol/L)']  # Target variable\n",
        "\n",
        "# Step 1: Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 2: Perform train-test split on the scaled data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now you can use X_train and X_test for model training and evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLsvqt55qoGJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Initialize Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'R2 Score: {r2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')"
      ],
      "metadata": {
        "id": "TdrBUyb4CYE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "eFcuim2fCsxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance from Random Forest\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Create a bar plot of feature importance\n",
        "plt.barh(feature_names, importances)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Feature Importance for Predicting Solubility')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Iq7I-kjisW5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot predictions vs actual\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "plt.xlabel('True Solubility')\n",
        "plt.ylabel('Predicted Solubility')\n",
        "plt.title('True vs Predicted Solubility (Best Model)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "koDLdTIBvrVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold Cross validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Features and target\n",
        "X = sol[['MolWt', 'LogP', 'NumRotatableBonds', 'NumHDonors', 'NumHAcceptors', 'AromaticProportion']]  # Features\n",
        "y = sol['measured log(solubility:mol/L)']  # Target variable\n",
        "\n",
        "# Initialize Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Set up cross-validation (e.g., 5-fold cross-validation)\n",
        "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "# Perform cross-validation and get the scores (e.g., R² for regression)\n",
        "cv_scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"Cross-validation R² scores:\", cv_scores)\n",
        "print(\"Mean R² score:\", np.mean(cv_scores))\n",
        "print(\"Standard Deviation of R² scores:\", np.std(cv_scores))\n"
      ],
      "metadata": {
        "id": "vyqk6QEgyAAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "train_sizes, train_scores, val_scores = learning_curve(model, X, y, cv=5)\n",
        "\n",
        "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
        "plt.plot(train_sizes, np.mean(val_scores, axis=1), label='Cross-validation score')\n",
        "plt.xlabel('Training Size')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.title('Learning Curves')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1T3fnY-uyjm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Solubility of the external unknown molecules.\n"
      ],
      "metadata": {
        "id": "Hq7RdMx95LhG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaX6mEkMrjWZ"
      },
      "outputs": [],
      "source": [
        "#loading new set of data to predict solubility of unknwon molecules using the model we build\n",
        "sol1 = pd.read_csv('https://raw.githubusercontent.com/Rajnishphe/AIDD-2022/main/ML%20Based%20QSAR/new_1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5qXqEoatKSg"
      },
      "outputs": [],
      "source": [
        "sol1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utsS9E_XtLbo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "# Define a function to calculate aromatic proportion\n",
        "def get_aromatic_proportion(mol):\n",
        "    aromatic_atoms = sum([1 for atom in mol.GetAtoms() if atom.GetIsAromatic()])\n",
        "    heavy_atoms = Descriptors.HeavyAtomCount(mol)\n",
        "    return aromatic_atoms / heavy_atoms if heavy_atoms > 0 else 0\n",
        "\n",
        "# Initialize empty lists for each descriptor\n",
        "mol_wt = []\n",
        "logp = []\n",
        "num_rot_bonds = []\n",
        "num_h_donors = []\n",
        "num_h_acceptors = []\n",
        "aromatic_proportion = []\n",
        "tpsa = []  # List to store TPSA values\n",
        "\n",
        "# Calculate descriptors\n",
        "for smiles in sol1['SMILES']:  # Loop through the SMILES column in your sol1 DataFrame\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    if mol is not None:\n",
        "        mol_wt.append(Descriptors.MolWt(mol))\n",
        "        logp.append(Descriptors.MolLogP(mol))\n",
        "        num_rot_bonds.append(Descriptors.NumRotatableBonds(mol))\n",
        "        num_h_donors.append(Descriptors.NumHDonors(mol))  # Corrected here\n",
        "        num_h_acceptors.append(Descriptors.NumHAcceptors(mol))\n",
        "        aromatic_proportion.append(get_aromatic_proportion(mol))\n",
        "        tpsa.append(Descriptors.TPSA(mol))  # Add TPSA calculation here\n",
        "    else:\n",
        "        mol_wt.append(None)\n",
        "        logp.append(None)\n",
        "        num_rot_bonds.append(None)\n",
        "        num_h_donors.append(None)\n",
        "        num_h_acceptors.append(None)\n",
        "        aromatic_proportion.append(None)\n",
        "        tpsa.append(None)  # Handle None case for TPSA\n",
        "\n",
        "# Add descriptors to the dataframe\n",
        "sol1['MolWt'] = mol_wt\n",
        "sol1['LogP'] = logp\n",
        "sol1['NumRotatableBonds'] = num_rot_bonds\n",
        "sol1['NumHDonors'] = num_h_donors\n",
        "sol1['NumHAcceptors'] = num_h_acceptors\n",
        "sol1['AromaticProportion'] = aromatic_proportion\n",
        "sol1['TPSA'] = tpsa  # Add TPSA to the DataFrame\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "sol1.to_csv('updated_sol1.csv', index=False)\n",
        "\n",
        "# Display the updated dataframe\n",
        "sol1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWKeV54htUwX"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Load model and scaler\n",
        "model = joblib.load('random_forest_model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')  # to make sure to do similar scaling\n",
        "\n",
        "X_sol1 = sol1[['MolWt', 'LogP', 'NumRotatableBonds', 'NumHDonors', 'NumHAcceptors', 'AromaticProportion']]\n",
        "X_sol1_scaled = scaler.transform(X_sol1)\n",
        "\n",
        "predicted_solubility = model.predict(X_sol1_scaled)\n",
        "sol1['Predicted_Solubility'] = predicted_solubility\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sol1"
      ],
      "metadata": {
        "id": "EtnuK978EWy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building model using lazyregressor\n",
        "!pip install lazypredict"
      ],
      "metadata": {
        "id": "vaMZ77ieyjoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "\n",
        "# Initialize LazyRegressor and fit the model\n",
        "regressor = LazyRegressor()\n",
        "models = regressor.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Display the performance of different models\n",
        "print(models)\n"
      ],
      "metadata": {
        "id": "48SvGQln3F0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}